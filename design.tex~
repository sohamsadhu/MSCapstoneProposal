\chapter{Hypothesis based on Hill Climbing to find near collisions}

%% Obviously you need to delete these lines when you have written up your text
%\begin{itemize}
%\item{} How you designed your solution
%\item{} Rationale for decisions
%\item{} Compare and contrast design with other approaches (related work) 
%\end{itemize}

\section{Finding near collisions with Hill Climbing}

A generic algorithm applied to find collisions, in reduced rounds of some SHA-3 competitors was Hill Climbing
\cite{00029}. Near collisions in which more than 75\% of the bits were same for two different messages, were found 
for reduced rounds of BLAKE-32, Hamsi-256 and JH. Near collision results are important for knowing the security
margins. In some cases, output of hash functions may be truncated for compatibility or efficiency purposes. In 
such cases near collisions could be improved to obtain collisions.

A $\epsilon / n $ bit near collision for hash function h and two messages $M_{1}$ and $M_{2}$, where $M_{1} \neq M_{2}$ can be 
defined as
\begin{center}$HW( h( M_{1}, CV ) \oplus h( M_{2}, CV ) ) = n - \epsilon $\end{center}
where HW is the Hamming weight, and CV is the chaining value, and n is the hash size in bits.

\begin{table}[h]
  \begin{center}
    \begin{tabular}{ | c | c | } \hline
      $\epsilon / n $                         & Complexity $( \approx )$ \\ \hline
      128 / 256, 256 / 512, 512 / 1024 & $2^{4}$ \\ \hline
      151 / 256, 287 / 512, 553 / 1024 & $2^{10}$ \\ \hline
      166 / 256, 308 / 512, 585 / 1024 & $2^{20}$ \\ \hline
      176 / 256, 323 / 512, 606 / 1024 & $2^{30}$ \\ \hline
      184 / 256, 335 / 512, 623 / 1024 & $2^{40}$ \\ \hline
      191 / 256, 345 / 512, 638 / 1024 & $2^{50}$ \\ \hline
      197 / 256, 354 / 512, 651 / 1024 & $2^{60}$ \\ \hline
    \end{tabular}
    \caption{Approximate complexity to find a $\epsilon / n$-bit near collision by generic random search}
  \end{center}
\end{table}

Hill Climbing starts with a random candidate, and then choosing a random successor that has a better fit to the
solution. In practice for message M and chaining value CV 
\begin{center}$HW( h(M, CV) \oplus h(M, CV + \delta) ) = n / 2 $,\end{center}
can be considered secure, where $\delta$ is n-bit vector with small Hamming weight. However, if the diffusion for the 
hash function h is not proper, then we obtain a lower Hamming weight. In such situation a correlation between two 
chaining values differing in small weight $\delta$ can obtain near collisions, with hill climbing algorithm.

Here, the aim of hill climbing algorithm will be to minimize the function 
\begin{center}$f_{M_{1}, M_{2}}(x) = HW( h(M_{1}, x) \oplus h(M_{2}, x) )$\end{center}
where $x \in \{0, 1\}^{n}$, where $M_{1}$ and $M_{2}$ are message blocks. CV is chosen as any random chaining value. Then the 
set of k-bit neighbours for the CV, will be 
\begin{center}$S^{k}_{CV} = \{ x \in \{0, 1\}^{n} \mid HW( CV \oplus x ) \leq k \}$\end{center}
where 
\begin{center}$ size \thickspace of \thickspace S^{k}_{CV} = \displaystyle \sum \limits_{i = 0}^{k} \begin{pmatrix} n \\ i \end{pmatrix}$.\end{center}
The k-opt condition can be defined as 
\begin{center}$f_{M_{1}, M_{2}} (CV) =  \min\limits_{x \in S^{k}_{CV}} f_{M_{1}, M_{2}} (x)$\end{center}
We can now describe algorithm 5.1, that is used in hill climbing algorithm to find the nearest match. 

\begin{algorithm}
  \caption{ Hill Climbing algorithm ($M_{1}, M_{2}, k$) }
  \begin{algorithmic}[1]
    \State Randomly select CV
    \State $f_{best} = f_{M_{1}, M_{2}}(CV)$
    \State \While {(CV is not k-opt)}
    \State CV = x such that $x \in S^{k}_{CV}$ with $f(x) < f(best)$
    \State $f_{best} = f_{M_{1}, M_{2}}(CV)$
    \State \EndWhile
    \State \Return (CV, $f_{best}$)
  \end{algorithmic}
\end{algorithm}

Given two message $M_{1} \thickspace and \thickspace M_{2}$, and a randomly chosen chaining value CV, the $f_{M_{1}, M_{2}}(CV)$
is obtained. The set $S^{k}_{CV}$ is searched for a better fit CV, and if found is updated. And the search is repeated again
in the k-bit neighbourhood of new CV.

There are two ways of choosing the next best CV, one by choosing the first chaining value that has a lower $f$ value, the
greedy way. And another by choosing the best chaining value amongst $S^{k}_{CV}$, which is steepest ascent. The algorithm
terminates once we get k-opt chaining value.

\section{Tabu Search, Simulated Annealing and Random search}

\subsection{Simulated Annealing}

\begin{algorithm}
  \caption{ Simulated Annealing Algorithm for obtaining near collisions }
  \begin{algorithmic}[1]
    \Function {Simulated-annealing}{$M_{1}, M_{2}, CV,$ schedule}
      \State current $\gets \thickspace CV$
      \For { t = 1 to $\infty$ }
        \State T $\gets$ schedule( t )
        \If { T = 0}
          \State \Return current
        \EndIf
        \State next $\gets$ a randomly selected successor from set $S^{k}_{current}$
        \State $\Delta E \gets  \thickspace f_{M_{1}, M_{2}}(current) - f_{M_{1}, M_{2}}(next)$
        \If { $\Delta$E $>$ 0 }
          \State current $\gets$ next
        \Else
          \State current $\gets$ next, with probability $e^{\Delta E / T}$
        \EndIf
      \EndFor
    \EndFunction
  \end{algorithmic}
\end{algorithm}

The problem with hill climbing, is that it can get locked in the local maxima, and fail to get the global maxima.
This is due to hill climbing not taking a downhill or a step with lower value. However, if hill climbing is 
tweaked to combine with random walk, then the problem of local maxima can be avoided. Simulated annealing picks
a random successor, and accepts it if the value is higher than previous. However, if the successor has a lower
value, then it is accepted with a probability less than 1. The probability has an exponential decrease proportional
to the decreased value of the move, and the temperature. Thus at higher temperature or at the initial stages, a
downhill successor is more likely to be accepted, than in the later stages \cite{00033}.

\subsection{Tabu Search}

\begin{algorithm}[h]
  \caption{ Tabu Search for obtaining near collisions \cite{00036}}
  \begin{algorithmic}[1]
    \Function {Tabu-search}{$TabuList_{size}, M_{1}, M_{2}, CV$}
      \State $S_{best}$ $\gets \thickspace CV$
      \State $TabuList \thickspace \gets$ null
      \While {$S_{best}$ not k-opt}
        \State CandidateList $\gets$ null
        \State $S_{neighbourhood} \gets S^{k}_{S_{best}}$
        \For { $S_{candidate} \in S_{best_{neighbourhood}}$}
          \If {not ContainsAnyFeatures( $S_{candidate}, TabuList$ )} 
            \State CandidateList $\gets$ $S_{candidate}$
          \EndIf
        \EndFor
        \State $S_{candidate}$ $\gets$ LocateBestCandidate( CandidateList )
        \If { Cost( $S_{candidate}$ ) $\leq$ Cost( $S_{best}$ ) }
          \While { $TabuList >TabuList_{size}$ }
            \State DeleteFeature( $TabuList$ )
          \EndWhile
        \EndIf
      \EndWhile 
      \State \Return $S_{best}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

Tabu search implements the neighbourhood search for the solutions, until the termination condition. The algorithm
uses a fixed amount of memory, to keep note of states, visited some fixed amount of time in past. The idea behind
keeping the state, is to restrict the search, to states that have not been visited previously. The algorithm can be
tweaked, to accept moves in tabu list through aspiration criteria, or inferior moves just to explore new possible
states. Tabu search has been applied to mostly combinatorial optimization problems\cite{00034, 00035}.

\begin{algorithm}[h]
  \caption{ Random selection from k-bit neighbourhood of $CV$ }
  \begin{algorithmic}[1]
    \Function {Random-Selection}{$ M_{1}, M_{2}, CV,$ number\_of\_trials}
      \State current $\gets \thickspace CV$
      \State trial $\gets$ 0
      \While { trial $<$ number\_of\_trials }
        \State next $\gets$ randomly selected candidate from $S^{k}_{current}$
        \If { $f_{M_{1}, M_{2}}(next) - f_{M_{1}, M_{2}}(current) $ }
          \State current $\gets$ next
        \EndIf
      \EndWhile 
      \State \Return current
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{Hypothesis}

\begin{center}
  \framebox
  {
    \parbox{400pt}
    {
      \centering \textsc{Hypothesis} \\
      \begin{itemize}
      \item Reduced state Keccak, has better resistance to near collisions than BLAKE and Gr{\o}stl. For the
      attack algorithms hill climbing, simulated annealing, tabu search and random selection.
      \item Simulated annealing and tabu search, are better at finding near collisions compared to hill 
      climbing and random selection.
      \end{itemize}
      %Reduced round Keccak, will have better resistance to near collisions found by tabu search and simulated
      %annnealing, compared to reduced round BLAKE and Gr{\o}stl.
    }
  }
\end{center}

As per the \href{"http://csrc.nist.gov/groups/ST/hash/sha-3/sha-3\_selection\_announcement.pdf"}{press release from NIST}, 
one of the reasons for choosing Keccak, was that it had a large security margin. All the five finalists from SHA-3 competition
were found to be secure and have good security margins. However there has not been much study, on the comparative security
margins for the candidate's reduced versions. Hill climbing has been shown as good generic greedy algorithm to find 
near collisions for reduced versions of some SHA-3 candidates. A generic algorithm does not exploit the inner permutations
or construction, of a hash function. Rather takes a good guess approach, to what the solution can be depending on the fitness
of the candidate solution. Thus making it an ideal tool to test on any hash function, irrespective of its design. In addition
to hill climbing, it would also be interesting to observe the success other variations of generic algorithms like Tabu search,
or Simulated Annealing will be able to get, and compare those results against a random search. In theory for an ideal hashing
function the performance of the generic algorithm will be equivalent to the random search algorithm on an average.

Comparative studies on SHA-3 candidates have been using the statistical test suites provided by NIST to check any 
deficiencies \cite{00030} \cite{00032}. Other than particular attacks like zero-sum property has been tested on 
Keccak and Blue Midnight Wish \cite{00031}.

\newpage

\section{Design of the Experiment}

The hill climbing algorithm will run on the same message pairs, for all the three candidates. The chaining value for
those pairs, will be updated, but would be kept constant for the same experiment.

  \subsection{Data}
  
  For creating the message pair, I intend to choose the first message as "The quick brown fox jumps over the lazy dog.".
  The initial message contains all the letters of the English alphabet, and seems a good candidate for testing the hash.
  Another 14 messages will be created from the initial message, so in all we get $\begin{pmatrix} 15 \\ 2 \end{pmatrix}
  = 105$ pairs of message in total. The rest of the 14 messages will be derived from the first message by applying a
  shift register operation, that results in a bit flip from the previous message. For example, if my initial message has
  a bit pattern of 0000. Then the subsequent messages will be 1000, 1100, 1110 and 1111.

  This will give the experiment an advantage of comparing substantial message pairs with small to medium hamming distance.
  The initial chaining value for experiment is chosen randomly, and does not matter as long it is kept constant provided
  to all the message pairs in the experiment. Hill climbing algorithm is supposed to refine the initial chaining value,
  to the solution, which is why choice of it is not a large factor. I intend to use the hash value of empty string generated
  by Keccak as the initial chaining value for all the pairs.

  \subsection{Procedure}

  Both Keccak and Gr$\o$stl can support variable byte message digest length, but BLAKE based on SHA-2 designs can have
  message digests of 224, 256, 384 and 512 bits. Thus the experiment for 105 pairs will be done on 4 message sizes as
  indicated by BLAKE. Keccak does not have a initial state or a chaining value as such, but can be tweaked, so that it
  has the first sponge state to accept the chaining value and pre-compute it and then apply the hash function on the
  message.

  Defining the reduced rounds for each of the functions is a bit tricky. Since for each the permutation function behaves
  differently, and so arbitrarily reducing the number of rounds, for each function to a number. May not create a level
  playing field for the comparison. But, for the purposes of experiment right now, I intend to just have 2 rounds for 
  each of the candidate hash functions. The number of rounds may be tweaked as found suitable during the course of 
  experiment.
