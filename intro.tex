\chapter{Introduction}

\section{Cryptographic Hash Functions}

A cryptographic hash function, is a function that accepts an arbitrarily long input string, and outputs
a fixed length string that is uniquely related to the input string. The output string is either called message
digest, or hash value of the given input string. Hash functions should be one way, that is given the message
digest, it should not be possible to find the input string. Two input strings even differing in a single
bit should output two different hash values, that are not close or display any co-relation to each other.

\section{The need for cryptographic hash function} 

Digital signatures are method of authenticating electronic documents, and hash functions are used to ease the
process of digitally signing a document. Digital signatures based on asymmetric algorithm like
RSA, have a input size limitation of around 128 to 324 bytes. However most documents in practice are
longer than that \cite{00017}.

One approach would be to divide the message into blocks of size acceptable by that of the signing 
algorithm, and sign each block separately. However, the cons to approach are following.

\begin{enumerate}
  \item \emph{Computationally intensive:} Modular exponentiation of large integers used in asymmetric
  algorithms are resource intensive. For signing, multiple blocks of message, the resource utilization
  is pronounced. Additionally, not only the sender but the receiver will also have to do the same resource
  intensive operations.
  \item \emph{Overheads:} The signature is of the same length as the message. This increases the overheads
  in storage and transmission.
  \item \emph{Security concerns:} An attacker could remove, or reorder, or reconstruct new message and 
  signatures from the previous message and signature pairs. Though attacker, cannot manipulate the individual
  blocks, but safety of the entire message is compromised.
\end{enumerate}

Thus to eliminate the overheads, and security limitations; a method is required to uniquely generate fixed
size finger print of arbitrarily large message blocks. Hash functions, fill this void of signing large messages.

\section{Standards and NIST Competition} 

  \subsection{Secure Hashing Algorithm SHA-0 and SHA-1}

  In 1993 National Security Agency(NSA) proposed SHA-0 as standard hashing algorithm, which was later
  standardised by NIST. However by 1995, Florent Chabaud and Antoine Joux, found collisions in SHA-0 
  with complexity of $2^{61}$. In 2004, Eli Biham and Chen found near collisions for SHA-0, about 142 
  out of 160 bits to be equal. Full  collisions were also found, when the number of rounds for the 
  algorithm were reduced from 80 to 62.

  In 1995 SHA-0 was replaced by SHA-1 designed by NSA \cite{00006, 00007}. It has block size of 512 bits
  and output of 160 bits, which is similar to that of SHA-0. SHA-1 has an additional circular shift operation, 
  that rectifies the weakness in SHA-0.

  In 2005 a team from Shandong University in China consisting of Xiaoyun Wang, Yiqun Lisa Yin, 
  and Hongbo Yu, found a way to find collisions on full version of SHA-1 requiring $2^{69}$ operations. 
  This is less than the number of operations required by brute force search for finding colliisions, which
  is $2^{80}$ \cite{00010}. An ideal hash function requires the number of operations to find a collision 
  to be equal to a brute force search, to be considered secure. 

  In October 2012, Jesse Walker from Skein team estimated the computational cost for finding collisions 
  in SHA-1 to be \$ 2.77 million, based on HashClash developed by Marc Stevens \cite{00008}.

  \begin{table}[h]
    \begin{center}
    \begin{tabular}{ *{5}{c} }
      \hline
      Algorithm & Message Size & Block Size & Word Size & Hash Value Size \\ \hline \hline
      SHA-1   & \textless $2^{64}$  bits & 512  bits & 32 bits & 160 bits \\   
      SHA-224 & \textless $2^{64}$  bits & 512  bits & 32 bits & 224 bits \\   
      SHA-256 & \textless $2^{64}$  bits & 512  bits & 32 bits & 256 bits \\   
      SHA-384 & \textless $2^{128}$ bits & 1024 bits & 64 bits & 384 bits \\   
      SHA-512 & \textless $2^{128}$ bits & 1024 bits & 64 bits & 512 bits \\
      \hline
    \end{tabular}
    \caption{ Secure Hash Algorithms as specified in FIPS 180-2} 
  \end{center}
  \end{table}

  \subsection{SHA-2}

  SHA-2 was designed by NSA, and released in 2001 by NIST. It is a family of hash functions consisting of 
  SHA-224, SHA-256, SHA-384, SHA-512. Table 1.1 above gives a brief overview of specifications
  of SHA-1 and family of SHA-2 hash functions. The number suffix after the SHA acronym, 
  indicates the bit length, of the output of that hash function. Although SHA-2 family of algorithms
  were influenced by SHA-1 design, but the attacks on SHA-1 have not been successfully extended completely
  to SHA-2.

  Collisions for 22-step attack, on SHA-256 and SHA-512 were found with a probability of 1. Computational
  operations to find collisions for 23-step and 24-step for SHA-256 attack were $2^{11.5}$ and $2^{28.5}$ 
  respectively. For SHA-512 reduced versions of 23 and 24 step, the corresponding values for were 
  $2^{16.5}$ and $2^{32.5}$ \cite{00012}. Here steps, are analogous to rounds of compression
  on the input given. Since, SHA-2 family relies on the $Merkle-Damg\dot{a}rd$ construction, the whole
  process of creation of hash can be considered as repeated application of certain operations generally called
  as compression function, on the input cumulatively. The steps here refer to the number of rounds of
  compression applied to the input.

  Preimage attacks on reduced versions of 41-step SHA-256 and 46-step SHA-512 have been found. As per the
  specifications, SHA-256 consisted of 64 rounds, while SHA-512 consisted of 80 rounds \cite{00011}. As, it
  can be seen, the SHA-2 functions can be said as partially susceptible to preimage attacks.

  \subsection{NIST competition and SHA-3}

  In response to advances made in cryptanalysis of SHA-2. NIST through a Federal Register Notice announced 
  a public competition on November 2, 2007. For a new cryptographic hash algorithm, that would be SHA-3.
  Submission requirements stated to provide a cover sheet, algorithm specifications and supporting
  documentation, optimized implementations as per specifications of NIST, and intellectual property statements.

  Submissions for the competition were accepted till October 31, 2008, and 51 candidates from 64 submissions
  for first round of competition were announced on December 9, 2008. On October 2, 2012 NIST announced the 
  winner of the competition to be Keccak, amongst the other four finalist, which were BLAKE, Gr{\o}stl, JH
  and Skein. Keccak was chosen for its' large security margin, efficient hardware implementation, and 
  flexibility.
