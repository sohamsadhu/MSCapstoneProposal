\chapter{Related work}

%From the wolfram alpha pages what is a field. A field is one that have field axioms of associativity, distributivity,
%commutativity, inverse, identity(else you cannot have the inverse). A field with finite elements or field order is finite
%or Galois field. GF(p) where the Galois field of order p. The order of the field is a power of a prime number. A GF 
%consists of residue classes of modulo p. Now a residue can be a congruence b mod n, then b is the residue. A finite
%field will have limited number of residues, which will form a residue class. The residue classes of a function x is
%all possible values of residue of f(x)(mod n). Galois fields are made of residues of the modulus function, so the 
%equivalence is based on the modulus function.

%OK, another thing, that I learned about in past few days was about Galois field. Why Galois field? Well, the thing
%is they are the building blocks to what is there in the cryptographic function. What did I learn about field, that
%number of elements in field are limited for the modulo of the prime that is the order of the field. Since it is
%modulo, so all the elements repeat with the numbers. The elements in a field obey the axioms of field that include
%associativity, distributive, commutative, inverse and identity. The modulo prime can be represented as a polynomial
%of odd powers summing to the power of the prime power of the field. The polynomial has to be irreducible, since if
%you allow reducible polynomial there is a possibility, that the polynomials would sum to the modulo and become a zero
%element that cannot be allowed to happen. Since multiplication with zero will be zero. Other than that, figuring
%out a inverse in field is hard but if you have the look up tables of logarithms with the generator numbers whose 
%successive powers modulo the prime generates all the numbers in the field. This table is then made as a look up,
%when you multiply the polynomials. There is a already algorithm and code written up for that thing. Which can be used.

%Well in this case in the first part the rant is about how not to get the security of the hash function not to be 
%based on the length of the message digest. Why so? Well then you cannot say anything about the security of the 
%function if the output of it changes from time to time. So you use the sponge function to make claims about the security.
%Please note in mind that they are saying that sponge is close to random oracle and only exception of internal
%collisions.

\section{Zero Sum Distinguishers}
Zero sum distinguishers were first presented in CHES 2009 rump session \cite{00014}. A zero sum distinguisher, for any
function is a way to find a set of values, that sum to zero, such that their respective images also sum to zero.

\section{Cryptanalysis done on Keccak}

\subsection{Rotational cryptanalysis of round-reduced KECCAK} \cite{00022}
In this paper, Paweł Morawiecki, Josef Pierpzyk and Marian Srebrny apply rotational cryptanalysis to Keccak. 
They use it to construct a 5-round distinguisher for Keccak-f[1600] and to do preimage generation for 4 rounds of 
Keccak[r=1024,c=576] truncated to 512 bits with complexity 2506 calls to Keccak-f[1600].

\subsection{New Attacks on Keccak 224 and Keccak 256} \cite{00023}
The authors of this paper present practical-time collisions on Keccak[r=1088,c=512] (and lower capacity) with 4 rounds. 
They combine a low-weight trail over 3 rounds with algebraic techniques.

\subsection{Practical Analysis of Reduced Round Keccak} \cite{00024}
In this paper, the authors propose several practical-time attacks on the Keccak hash function with 2 to 4 rounds. 
First, they give a differential distinguisher exploiting a low-weight differential trail. Its complexity is 225 for 4 
rounds. Then, they show how to produce a collision (resp. near-collision) on 2 (resp. 3) rounds of Keccak[r=1088,c=512] 
(and lower capacity) with complexity 233 (resp. 225). Finally, they present an algorithm to find (second) preimages in 
time 231 and memory 229.

\subsection{Unaligned Rebound Attack: Application to Keccak} \cite{00025}
This paper analyzes two aspects of differential cryptanalysis on Keccak: efficient trails and rebound attacks. In the 
former, the authors propose a heuristic to build differential trails with a low restriction weight. For Keccak-f[1600], 
they obtained trails of weight 32, 142 and 709 for 3, 4 and 5 rounds, respectively. In the latter, the paper presents 
distinguishers making use of the rebound attack for up to 8 rounds of Keccak-f[1600] with a complexity of 2491.

\subsection{Improved zero-sum distinguisher for full round Keccak-f permutation} \cite{00026}
The authors of this paper noted a property of the inverse of the non-linear function χ: while χ-1 has algebraic degree 3,
the product of any two output bits also has degree 3. This allows to estimate the degree of the Keccak-f rounds more tightly 
and to extend the zero-sum distinguisher on Keccak-f[1600] to size 21575 for 24 rounds.

\subsection{A SAT-based preimage analysis of reduced Keccak hash functions} \cite{00027}
In this paper, Paweł Morawiecki and Marian Srebrny report on experiments for generating preimages using SAT solvers. 
They attack Keccak versions calling Keccak-f with width 50, 200 and 1600 and with a reduced number of rounds. 
They compare the SAT solver approach with plain exhaustive search and it turns out to be faster for up to 3 rounds.

\subsection{Zero-sum Distinguishers for Iterated Permutations and Application to Keccak-f and Hamsi-256} \cite{00028}
In this paper, Christina Boura and Anne Canteaut extend their zero-sum distinguishers to 20 rounds.

\section{Cryptanalysis done on BLAKE}
\section{Cryptanalysis done on Gr$\o$stl}
