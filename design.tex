\chapter{Related work and hypothesis based on Hill Climbing to find near collisions}

\section{Rotational cryptanalysis of round-reduced KECCAK}

Rotational cryptanalysis\cite{00041} is used to to follow relation between states $(A, A^{\leftarrow})$ of 
KECCAK-f[1600] in course of their transformation, and thus derive a distinguisher.

\begin{defn}
A pair of two 1600-bit states $(A, A^{\leftarrow})$ is called rotational pair when each lane in state $A^{\leftarrow}$
is created by bitwise rotation of operation of corresponding lane in state $A$. The operation moves the bit from 
position $(x, y, z)$ to the position $(x, y, z + n)$, where z + n is done on modulo 64. $x$ and $y$ values range from 0 
to 4, and $z$ value ranges from 0 to 63. $n$ is the rotational number and is same for every lane. Thus rotational pairs
are $\forall(x, y, z) : A_{(x, y, z)} = A^{\leftarrow}_{(x, y, z + n)}$ \cite{00022}.
\end{defn}

\begin{defn}
Set $S_n$ is a set of $2^{1600}$ pairs of states which are created by an operation of KECCAK-f[1600] applied to all
possible rotational pairs \cite{00022}.
\end{defn}

\begin{defn}
Probability $p^{n}_{(x, y, z)}$ is the probability for pair of states $(A, A^{\leftarrow})$ randomly selected from the
set $S_n$ we have $A_{(x, y, z)} = A^{\leftarrow}_{(x, y, z + n)}$ \cite{00022}.
\end{defn}

\begin{defn}
Given probability distribution $\mathcal{D}_n$ that assigns probability $\frac{1}{n!}$ for each $p \in \mathcal{P}_n$.
A permutation is called random if it is chosen according to uniform distribution $\mathcal{D}_n$ \cite{00022}.
\end{defn}

It is assumed that random permutation $p^n_{(x, y, z)}$ follows binomial distribution $\mathcal{B}(t, s)$ where $t$ is
trials and $s$ is success probability that is equal to 0.5. Experimental results for a chosen $p_{(x, y, z)}$ are 
compared to follow distribution $\mathcal{B}(t, s)$. The experimental values are supposed to fall within range of 
$0.5t\pm2\sigma$ with 95\% confidence interval.

The probability change through steps of Keccak, can be derived from analysis of bitwise operation. It is assumed
that corresponding bits from $(A, A^{\leftarrow})$ are equal, both combinations ('00' or '11') or opposite combinations
have same probability to be actual values. Operations like NOT, or rotation in Keccak do not affect the probabilities,
so only probabilities for AND and XOR are considered.

\begin{lem}
Given input bits a, b and output bit out; with $p_a$ and $p_b$ defined as per definition 4.1.3, then for AND operation
$P_{out} = \frac{1}{2}(p_{a} + p_{b} - p_{a} p_{b})$ \cite{00022}
\end{lem}

\begin{lem}
Given input bits a, b and output bit out; with $p_a$ and $p_b$ defined as per definition 4.1.3, then for XOR operation
$P_{out} = p_{a} + p_{b} - 2 p_{a} p_{b}$ \cite{00022}
\end{lem}

A 4 round rotational was built, that found some values deviate from the 0.5 like $p^{54}_{(4, 4, 14)} = 0.5625$. 10,000
random samples of rotational pairs are ran on 4 round KECCAK-f[1600]. The mean from that sample is 5682 which is beyond
range from mean of $\mathcal{B}(10000, 0.5)$ which is 5000$\pm$2.5. Thus demonstrating a distinguisher for 4 rounds.
After 4 rounds $p^n_{(x, y, z)} = 0.5$, and hence the distinguisher cannot be directly extended. But instead probability
that relation between two pairs of states $(A_{(x, y, z)}, A^{\leftarrow}_{(x, y, z+n)})$ and 
$(A_{(x, y', z)}, A^{\leftarrow}_{(x, y'', z+n)})$ are observed, that should follow distribution $\mathcal{B}(10000, 0.5)$.
Values for $p^{63}_{(2, 1, 37)}$ and $p^{63}_{(2, 2, 37)}$ have the highest deviation from 0.5 at end of fourth round. The
probability that they are in the same relation is given by $p^n_{(x, y, z)} \dot p^n_{(x, y'', z)} + (1 - p^n_{(x, y, z)})
(1 - p^n_{(x, y, z)})$ which comes to 0.499024. The $\rho$ and $\pi$ steps in Keccak only change the position of the
probability to bit pairs $(A_{(1, 2, 43)}, A^{\leftarrow}_{(1, 2, 44)})$ and $(A_{(2, 0, 16)}, A^{\leftarrow}_{(2, 0, 17)})$.
The bias is observed by generating sufficient number of samples 'm' based on Chernoff bound based on inequality 
\[ m \geq \frac{1}{(P_c - 0.5)^2} \ln \frac{1}{\sqrt \in}\]
where $\in$ is error set to 0.05, thus value of m turns out to be 403,000,000. Based on this value algorithm 4.1 is implemented.
  \begin{algorithm}
  \begin{algorithmic}[1]
    \State Generate 403,000,000 rotational pairs.
    \ForAll{403,000,000 rotational pairs}
      \State Run Keccak for 5 rounds on states $A$ and $A^{\leftarrow}$.
      \If{$(A_{(1, 2, 43)} \oplus A^{\leftarrow}_{(1, 2, 44)} \oplus A_{(2, 0, 16)} \oplus A^{\leftarrow}_{(2, 0, 17)} = 0)$}
      \State mean := mean + 1
      \EndIf
    \EndFor
    \State \Return mean
  \end{algorithmic}
  \caption[Find pair probabililty]{Find pair probabililty \cite{00022}}
  \label{alg:seq}
  \end{algorithm}

The mean for $\mathcal{B}(403000000, 0.5)$ with the standard deviation has range of 201,500,000$\pm$2.10037, but 
experimentally from implementing algorithm 4.1, it comes to around 201,450,503, thus concluding this as a distinguisher.

For the preimage attack an unknown message with cyclical pattern like that of 4 0's followed by 4 1's alternatively, of
512 bits is chosen. There are 256 possible messages of the cyclic pattern. For the preimage attack, a rotational
counterpart of the preimage is searched for, that would reduce the complexity from random search. Algorithm 4.2 describes
the steps.

\begin{algorithm}[H]
\begin{algorithmic}[1]
  \State Guess first 8 lanes of $A^{\leftarrow}$
  \State Run Keccak-f[1600] for 3 rounds on state $A^{\leftarrow}$
  \For {for n := 0 to n \textless 64}
    \State candidate := true
    \For{10 sets of cordinates $(x, y, z)$ being on list created on precomputation}
      \If{$(p^n_{(x, y, z)} = 1)$ and $(A_{(x, y, z)} = A^{\leftarrow}_{(x, y, z)})$}
        \State candidate := false
      \EndIf
      \If{$(p^n_{(x, y, z)} = 0)$ and $(A_{(x, y, z)} \neq A^{\leftarrow}_{(x, y, z)})$}
        \State candidate := false
      \EndIf
    \EndFor
    \If{ candidate = true }
      \State Rotate the guessed state by n bits.
      \State Verify input to Keccak, that runs for 3 rounds.
    \EndIf
  \EndFor
\end{algorithmic}
\caption[Preimage for 3 round Keccak for unknown cyclic input]
{Preimage for 3 round Keccak for unknown cyclic input \cite{00022}}
\label{alg:seq}
\end{algorithm}

For a given state there are 64 possible rotational pairs, derived from length of lane. We are searching for preimage
of 512 bits, thus the probability of guessing the rotational counterpart $A^{\leftarrow}$ is $2^{-512} \cdot 64 = 2^{-506}$,
or rather $2^{506}$ guesses. There are $2^{256}$ messages possible of the cyclic pattern that we consider here. There
are 10 sets of $(x, y, z)$ cordinates for each of the rotational number. The probability of the candidate having 
$p^n_{(x, y, z)}$ similar to that on list is $2^{-10}$. So $2^{512} / 2^{10} = 2^{502}$ number of checks are required
at most to find the candidate. Thus the total work is equivalent to $2^{506}$ calls to KECCAK-512 for 3 rounds to find
the preimage.

The above method for finding the preimage cannot be directly extended to 4 rounds since $\iota$ operation in Keccak
renders $p^n_{(x, y, z)} \neq 0, 1$. To overcome this, the rotational state is ran on modified Keccak-512 for four rounds
which does not implement $\iota$ function. Algorithm 4.3 is for finding preimage.

\begin{algorithm}[H]
\begin{algorithmic}[1]
  \State Choose 512 bits at random for state $A^{\leftarrow}$
  \State Run KECCAk-f[1600] without the $\iota$ transformation is run on them.
  \For {for n:= 0 to n \textless 64}
    \State candidate := true
    \For{9 sets of cordinates $(x, y, z)$ that are in list created from precomputation}
      \If{$(p^n_{(x, y, z)} = 0)$ and $(A_{(x, y, z)} \neq A^{\leftarrow}_{(x, y, z+n)})$}
        \State candidate := false
      \EndIf
      \If{$(p^n_{(x, y, z)} = 1)$ and $(A_{(x, y, z)} = A^{\leftarrow}_{(x, y, z+n)})$}
        \State candidate := false
      \EndIf
    \EndFor
    \If{ candidate = true }
      \State Rotate the guessed state by n bits.
      \State Verify input to Keccak, that runs for 4 rounds of modified Keccak-512.
    \EndIf
  \EndFor
\end{algorithmic}
\caption[Preimage for 4 round Keccak for unknown cyclic input without $\iota$ function in Keccak]
{Preimage for 4 round Keccak for unknown cyclic input without $\iota$ function in Keccak \cite{00022}}
\label{alg:seq}
\end{algorithm}

Just like the 3 round preimage finding method, the above method for finding the preimage for 4 rounds has complexity of
$2^{506}$ calls to Keccak-512.

\section{Finding near collisions with Hill Climbing}

Hill climbing algorithm, was used to find near collisions in reduced rounds of some SHA-3 competitors \cite{00029}.
Near collisions in which more than 75\% of the bits were same for two different messages, were found 
for reduced rounds of BLAKE-32, Hamsi-256 and JH. Near collision results are important for knowing the security
margins. Hash values are sometimes truncated for compatibility or efficiency purposes. The findings from near collision
can be improved to obtain full collisions.

A $\epsilon / n $ bit near collision for hash function h and two messages $M_{1}$ and $M_{2}$, where $M_{1} \neq M_{2}$ can be 
defined as
\begin{center}$HW( h( M_{1}, CV ) \oplus h( M_{2}, CV ) ) = n - \epsilon $\end{center}
where HW is the Hamming weight, and CV is the chaining value, and n is the hash size in bits.

\begin{table}[h]
  \begin{center}
    \begin{tabular}{ | c | c | } \hline
      $\epsilon / n $                         & Complexity $( \approx )$ \\ \hline
      128 / 256, 256 / 512, 512 / 1024 & $2^{4}$ \\ \hline
      151 / 256, 287 / 512, 553 / 1024 & $2^{10}$ \\ \hline
      166 / 256, 308 / 512, 585 / 1024 & $2^{20}$ \\ \hline
      176 / 256, 323 / 512, 606 / 1024 & $2^{30}$ \\ \hline
      184 / 256, 335 / 512, 623 / 1024 & $2^{40}$ \\ \hline
      191 / 256, 345 / 512, 638 / 1024 & $2^{50}$ \\ \hline
      197 / 256, 354 / 512, 651 / 1024 & $2^{60}$ \\ \hline
    \end{tabular}
    \caption{Approximate complexity to find a $\epsilon / n$-bit near collision by generic random search \cite{00029}}
  \end{center}
\end{table}

Hill Climbing starts with a random candidate, and then choosing a random successor that has a better fit to the
solution. In practice for message M and chaining value CV 
\begin{center}$HW( h(M, CV) \oplus h(M, CV + \delta) ) = n / 2 $,\end{center}
can be considered secure, where $\delta$ is n-bit vector with small Hamming weight. However, if the diffusion for the 
hash function h is not proper, then we obtain a lower Hamming weight. In such situation a correlation between two 
chaining values differing in small weight $\delta$ can obtain near collisions, with hill climbing algorithm.

Here, the aim of hill climbing algorithm will be to minimize the function 
\begin{center}$f_{M_{1}, M_{2}}(x) = HW( h(M_{1}, x) \oplus h(M_{2}, x) )$\end{center}
where $x \in \{0, 1\}^{n}$, where $M_{1}$ and $M_{2}$ are message blocks. CV can be chosen at random. The 
set of k-bit neighbours for the CV, can be defined as 
\begin{center}$S^{k}_{CV} = \{ x \in \{0, 1\}^{n} \mid HW( CV \oplus x ) \leq k \}$\end{center}
where 
\begin{center}$ size \thickspace of \thickspace S^{k}_{CV} = \displaystyle \sum \limits_{i = 0}^{k} \begin{pmatrix} n \\ i \end{pmatrix}$.\end{center}
The k-opt condition can be defined as 
\begin{center}$f_{M_{1}, M_{2}} (CV) =  \min\limits_{x \in S^{k}_{CV}} f_{M_{1}, M_{2}} (x)$\end{center}
The hill climbing algorithm to find the nearest match is described in algorithm 4.4. 

\begin{algorithm}
  \caption{ Hill Climbing algorithm ($M_{1}, M_{2}, k$) \cite{00029}}
  \begin{algorithmic}[1]
    \State Randomly select CV
    \State $f_{best} = f_{M_{1}, M_{2}}(CV)$
    \State \While {(CV is not k-opt)}
    \State CV = x such that $x \in S^{k}_{CV}$ with $f(x) < f(best)$
    \State $f_{best} = f_{M_{1}, M_{2}}(CV)$
    \State \EndWhile
    \State \Return (CV, $f_{best}$)
  \end{algorithmic}
\end{algorithm}

Given two message $M_{1} \thickspace and \thickspace M_{2}$, and a randomly chosen chaining value CV, the $f_{M_{1}, M_{2}}(CV)$
is obtained. The set $S^{k}_{CV}$ is searched for a better fit CV, and if found is updated. The search is repeated again
in the k-bit neighbourhood of new CV.

There are two ways of choosing the next best CV, one by choosing the first chaining value that has a lower $f$ value, the
greedy way. And another by choosing the best chaining value amongst $S^{k}_{CV}$, which is steepest ascent. The algorithm
terminates once we get k-opt chaining value.

\section{Tabu Search, Simulated Annealing and Random search}

\subsection{Simulated Annealing}

\begin{algorithm}
  \caption{ Simulated Annealing Algorithm for obtaining near collisions }
  \begin{algorithmic}[1]
    \Function {Simulated-annealing}{$M_{1}, M_{2}, CV,$ schedule}
      \State current $\gets \thickspace CV$
      \For { t = 1 to $\infty$ }
        \State T $\gets$ schedule( t )
        \If { T = 0}
          \State \Return current
        \EndIf
        \State next $\gets$ a randomly selected successor from set $S^{k}_{current}$
        \State $\Delta E \gets  \thickspace f_{M_{1}, M_{2}}(current) - f_{M_{1}, M_{2}}(next)$
        \If { $\Delta$E $>$ 0 }
          \State current $\gets$ next
        \Else
          \State current $\gets$ next, with probability $e^{\Delta E / T}$
        \EndIf
      \EndFor
    \EndFunction
  \end{algorithmic}
\end{algorithm}

The problem with hill climbing, is that it can get locked in the local maxima, and fail to get the global maxima.
This is due to hill climbing not taking a downhill or a step with lower value. However, if hill climbing is 
tweaked to combine with random walk, then the problem of local maxima can be avoided. Simulated annealing picks
a random successor, and accepts it if the value is higher than previous. However, if the successor has a lower
value, then it is accepted with a probability less than 1. The probability has an exponential decrease proportional
to the decreased value of the move, and the temperature. Thus at higher temperature or at the initial stages, a
downhill successor is more likely to be accepted, than in the later stages \cite{00033}.

\subsection{Tabu Search}

\begin{algorithm}[h]
  \caption{ Tabu Search for obtaining near collisions \cite{00036}}
  \begin{algorithmic}[1]
    \Function {Tabu-search}{$TabuList_{size}, M_{1}, M_{2}, CV$}
      \State $S_{best}$ $\gets \thickspace CV$
      \State $TabuList \thickspace \gets$ null
      \While {$S_{best}$ not k-opt}
        \State CandidateList $\gets$ null
        \State $S_{neighbourhood} \gets S^{k}_{S_{best}}$
        \For { $S_{candidate} \in S_{best_{neighbourhood}}$}
          \If {($\lnot$ContainsAnyFeatures( $S_{candidate}, TabuList$ ))} 
            \State CandidateList $\gets$ $S_{candidate}$
          \EndIf
        \EndFor
        \State $S_{candidate}$ $\gets$ LocateBestCandidate( CandidateList )
        \If { Cost( $S_{candidate}$ ) $\leq$ Cost( $S_{best}$ ) }
          \State $S_{best} \gets S_{candidate}$
          \State $TabuList \gets$ featureDifferences$(S_{candidate}, S_{best})$
          \While { $TabuList >TabuList_{size}$ }
            \State DeleteFeature( $TabuList$ )
          \EndWhile
        \EndIf
      \EndWhile 
      \State \Return $S_{best}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

Tabu search implements the neighbourhood search for the solutions, until the termination condition. The algorithm
uses a fixed amount of memory, to keep note of states, visited some fixed amount of time in past. The idea behind
keeping the state, is to restrict the search, to states that have not been visited previously. The algorithm can be
tweaked, to accept moves in tabu list through aspiration criteria, or inferior moves just to explore new possible
states. Tabu search has been applied to mostly combinatorial optimization problems \cite{00034, 00035}.

\begin{algorithm}[h]
  \caption{ Random selection from k-bit neighbourhood of $CV$ }
  \begin{algorithmic}[1]
    \Function {Random-Selection}{$ M_{1}, M_{2}, CV,$ number\_of\_trials}
      \State current $\gets \thickspace CV$
      \State trial $\gets$ 0
      \While { trial $<$ number\_of\_trials }
        \State next $\gets$ randomly selected candidate from $S^{k}_{current}$
        \If { $f_{M_{1}, M_{2}}(next) - f_{M_{1}, M_{2}}(current) $ }
          \State current $\gets$ next
        \EndIf
      \EndWhile 
      \State \Return current
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{Hypothesis}

\begin{center}
  \framebox
  {
    \parbox{400pt}
    {
      \centering \textsc{Hypothesis} \\
      \begin{itemize}
      \item Reduced state Keccak, has better resistance to near collisions than BLAKE and Gr{\o}stl. For the
      attack algorithms hill climbing, simulated annealing, tabu search and random selection.
      \item Simulated annealing and tabu search, are better at finding near collisions compared to hill 
      climbing and random selection.
      \item State size has no effect on efficiency of Keccak permutation rounds, for reduced number of rounds.
      \end{itemize}
    }
  }
\end{center}

As per the \href{"http://csrc.nist.gov/groups/ST/hash/sha-3/sha-3\_selection\_announcement.pdf"}{press release from NIST}, 
one of the reasons for choosing Keccak, was that it had a large security margin. All the five finalists from SHA-3 competition
were found to be secure and have good security margins. However there has not been much study, on the comparative security
margins for the candidate's reduced versions. Hill climbing has been shown as good generic greedy algorithm to find 
near collisions for reduced versions of some SHA-3 candidates. A generic algorithm does not exploit the inner permutations
or construction, of a hash function, rather it takes a good guess approach, to what the solution can be depending on the fitness
of the candidate solution. In addition to hill climbing, it would also be interesting to observe the success other 
variations of generic algorithms like tabu search, simulated annealing against random search, for reduced versions of 
hash function. In theory for an ideal hashing function the performance of the generic algorithm will be equivalent to 
the random search algorithm on an average.

Comparative studies on SHA-3 candidates have been using the statistical test suites provided by NIST to check any 
deficiencies \cite{00030, 00032}. Studies have also been done on attacks particular to hash function, like zero-sum
property for Keccak \cite{00031}, and rebound attack on JH \cite{00043}.
